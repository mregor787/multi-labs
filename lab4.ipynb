{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №4: Проведение исследований со случайным лесом"
      ],
      "metadata": {
        "id": "YHtz3AsnIMmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Выбор начальных условий"
      ],
      "metadata": {
        "id": "Zl8M_vt4ISju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Был проведен в ЛР №1."
      ],
      "metadata": {
        "id": "TxBoVQWwIUhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub scikit-learn numpy pandas matplotlib seaborn"
      ],
      "metadata": {
        "id": "tZDD51JEIWx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ConFthxZIYS_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачивание Date Fruit Dataset\n",
        "date_fruit_path = kagglehub.dataset_download(\"muratkokludataset/date-fruit-datasets\")\n",
        "\n",
        "# Чтение Excel-файла\n",
        "date_fruit_data = pd.read_excel(f\"{date_fruit_path}/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6P2jm9wIf6X",
        "outputId": "d16f3fc0-446e-490c-d85e-8f707a717971"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачивание Concrete Compressive Strength\n",
        "concrete_strength_path = kagglehub.dataset_download(\"niteshyadav3103/concrete-compressive-strength\")\n",
        "\n",
        "# Чтение CSV-файла\n",
        "concrete_data = pd.read_csv(f\"{concrete_strength_path}/Concrete Compressive Strength.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHWZnlmyIhvW",
        "outputId": "c8a645fe-8ec9-4903-f6a5-fb10069b7c7e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "MA8l3Ve7Ikve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, root_mean_squared_error, r2_score, make_scorer\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "ehWkjHaUInSc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделим датасет для классификации на обучающую и тестовую выборки"
      ],
      "metadata": {
        "id": "cJNkecImJIYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на признаки и целевую переменную\n",
        "X_class = date_fruit_data.drop(columns=['Class'])\n",
        "y_class = date_fruit_data['Class']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
        ")\n",
        "\n",
        "# Преобразование целевой переменной\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_class = label_encoder.fit_transform(y_train_class)\n",
        "y_test_class = label_encoder.transform(y_test_class)"
      ],
      "metadata": {
        "id": "rf9mKMwzJI9v"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогично разделим датасет для регрессии"
      ],
      "metadata": {
        "id": "JDAgoEYzJMz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на признаки и целевую переменную\n",
        "X_reg = concrete_data.drop(columns=['Concrete compressive strength '])\n",
        "y_reg = concrete_data['Concrete compressive strength ']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "zSYUgZWEJPt3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модели для классификации и регрессии из Sklearn и оценим их"
      ],
      "metadata": {
        "id": "joYM3CcCJSij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_classifier.fit(X_train_class, y_train_class)\n",
        "\n",
        "y_pred_class = rf_classifier.predict(X_test_class)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test_class, y_pred_class)\n",
        "f1_rf = f1_score(y_test_class, y_pred_class, average='weighted')\n",
        "\n",
        "print(f\"Random Forest Classifier - Accuracy: {accuracy_rf:.4f}, F1-Score: {f1_rf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcLM6sPEI9Oz",
        "outputId": "46033080-47e3-41dd-fc16-4c1a836f6769"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier - Accuracy: 0.9222, F1-Score: 0.9214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "y_pred_reg = rf_regressor.predict(X_test_reg)\n",
        "\n",
        "rmse_rf = root_mean_squared_error(y_test_reg, y_pred_reg)\n",
        "r2_rf = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"Random Forest Regressor - RMSE: {rmse_rf:.4f}, R²: {r2_rf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH21orPiJm1u",
        "outputId": "ee5d17e2-0894-46c2-ea2b-29d42e17d207"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor - RMSE: 5.5397, R²: 0.8809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, точность для встроенной в Sklearn модели случайного леса получилась отличной, в частности для регрессора, просто невероятной по сравнению с предыдущими ЛР (92.2% точности для классификатора, 5.53 RMSE для регрессора). Попробуем улучшить бейзлайн."
      ],
      "metadata": {
        "id": "IyImjQdfJ1ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "TjlxBY4mKLru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем перебирать гиперпараметры случайного леса, такие, как n_estimators, max_depth, min_samples_split, min_samples_leaf"
      ],
      "metadata": {
        "id": "-xsz5woOKNwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Сокращенный диапазон гиперпараметров\n",
        "param_grid_classifier = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "}\n",
        "\n",
        "param_grid_regressor = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "}\n",
        "\n",
        "# === Подбор гиперпараметров для RandomForestClassifier ===\n",
        "print(\"=== Random Forest Classifier - Hyperparameter Tuning ===\")\n",
        "grid_search_rf_classifier = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid_classifier,\n",
        "    scoring='accuracy',  # Используем Accuracy вместо F1-Score\n",
        "    cv=3,                # Уменьшаем количество фолдов\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search_rf_classifier.fit(X_train_class, y_train_class)\n",
        "\n",
        "# Лучшие параметры и результат\n",
        "best_params_rf_classifier = grid_search_rf_classifier.best_params_\n",
        "best_score_rf_classifier = grid_search_rf_classifier.best_score_\n",
        "\n",
        "print(f\"Лучшие параметры для Random Forest Classifier: {best_params_rf_classifier}\")\n",
        "print(f\"Лучший Accuracy на кросс-валидации: {best_score_rf_classifier:.4f}\")\n",
        "\n",
        "# === Подбор гиперпараметров для RandomForestRegressor ===\n",
        "print(\"\\n=== Random Forest Regressor - Hyperparameter Tuning ===\")\n",
        "grid_search_rf_regressor = GridSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_grid=param_grid_regressor,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=3,                # Уменьшаем количество фолдов\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search_rf_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Лучшие параметры и результат\n",
        "best_params_rf_regressor = grid_search_rf_regressor.best_params_\n",
        "best_score_rf_regressor = -grid_search_rf_regressor.best_score_\n",
        "\n",
        "print(f\"Лучшие параметры для Random Forest Regressor: {best_params_rf_regressor}\")\n",
        "print(f\"Лучший RMSE на кросс-валидации: {best_score_rf_regressor:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TirmPxz2KXIO",
        "outputId": "d90bc0f3-256a-4c9a-eb74-9c0ba722d7c1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Random Forest Classifier - Hyperparameter Tuning ===\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Лучшие параметры для Random Forest Classifier: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Лучший Accuracy на кросс-валидации: 0.8719\n",
            "\n",
            "=== Random Forest Regressor - Hyperparameter Tuning ===\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Лучшие параметры для Random Forest Regressor: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Лучший RMSE на кросс-валидации: 5.2606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модели с лучшими гиперпараметрами"
      ],
      "metadata": {
        "id": "UVw6saKJNGsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier с подобранными параметрами\n",
        "best_rf_classifier = RandomForestClassifier(\n",
        "    n_estimators=best_params_rf_classifier['n_estimators'],\n",
        "    max_depth=best_params_rf_classifier['max_depth'],\n",
        "    min_samples_split=best_params_rf_classifier['min_samples_split'],\n",
        "    min_samples_leaf=best_params_rf_classifier['min_samples_leaf'],\n",
        "    random_state=42\n",
        ")\n",
        "best_rf_classifier.fit(X_train_class, y_train_class)\n",
        "y_pred_class = best_rf_classifier.predict(X_test_class)\n",
        "\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "f1 = f1_score(y_test_class, y_pred_class, average='weighted')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F1-Score: {f1:.4f}\")\n",
        "\n",
        "# RandomForestRegressor с подобранными параметрами\n",
        "best_rf_regressor = RandomForestRegressor(\n",
        "    n_estimators=best_params_rf_regressor['n_estimators'],\n",
        "    max_depth=best_params_rf_regressor['max_depth'],\n",
        "    min_samples_split=best_params_rf_regressor['min_samples_split'],\n",
        "    min_samples_leaf=best_params_rf_regressor['min_samples_leaf'],\n",
        "    random_state=42\n",
        ")\n",
        "best_rf_regressor.fit(X_train_reg, y_train_reg)\n",
        "y_pred_reg = best_rf_regressor.predict(X_test_reg)\n",
        "\n",
        "rmse = root_mean_squared_error(y_test_reg, y_pred_reg)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "print(f\"Test R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5qgmzLQM4Ja",
        "outputId": "ecdd3dc4-2c73-4814-8505-869dc1fabe59"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9278\n",
            "Test F1-Score: 0.9281\n",
            "Test RMSE: 5.4444\n",
            "Test R²: 0.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, точность немного выросла, как для классификации, так и для регрессии."
      ],
      "metadata": {
        "id": "-Sk1QetQNKON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "6biptNuZNRxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем собственную реализацию случайного леса для классификации и регрессии, затем обучим модели на тестовых данных и сравним по качеству с реализациями из Sklearn. Будем использовать реализацию решающего дерева из ЛР №3."
      ],
      "metadata": {
        "id": "W5k0zOpsNUFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeNode:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature          # Признак для разбиения\n",
        "        self.threshold = threshold      # Пороговое значение\n",
        "        self.left = left                # Левое поддерево\n",
        "        self.right = right              # Правое поддерево\n",
        "        self.value = value              # Значение в листе (для терминальных узлов)\n",
        "\n",
        "class DecisionTreeClassifierCustom:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.root = None\n",
        "\n",
        "    def _gini(self, y):\n",
        "        proportions = np.bincount(y) / len(y)\n",
        "        return 1 - np.sum(proportions ** 2)\n",
        "\n",
        "    def _split(self, X, y, feature, threshold):\n",
        "        left_indices = np.where(X[:, feature] < threshold)[0]\n",
        "        right_indices = np.where(X[:, feature] >= threshold)[0]\n",
        "        return X[left_indices], y[left_indices], X[right_indices], y[right_indices]\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_score = float('inf')  # Лучший критерий разбиения (минимальный)\n",
        "        best_split = None\n",
        "\n",
        "        for feature in range(X.shape[1]):  # Перебор всех признаков\n",
        "            thresholds = np.unique(X[:, feature])  # Уникальные значения признака\n",
        "            for threshold in thresholds:\n",
        "                # Разбиение данных\n",
        "                X_left, y_left, X_right, y_right = self._split(X, y, feature, threshold)\n",
        "\n",
        "                # Проверка, что оба подмножества достаточно велики\n",
        "                if len(y_left) < self.min_samples_leaf or len(y_right) < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                # Вычисление критерия Gini\n",
        "                score = (len(y_left) * self._gini(y_left) + len(y_right) * self._gini(y_right)) / len(y)\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_split = (feature, threshold)\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        # Условие остановки\n",
        "        if (len(np.unique(y)) == 1 or depth == self.max_depth or\n",
        "            len(y) < self.min_samples_split):\n",
        "            return DecisionTreeNode(value=np.bincount(y).argmax())\n",
        "\n",
        "        # Найти лучшее разбиение\n",
        "        best_split = self._best_split(X, y)\n",
        "        if best_split is None:\n",
        "            return DecisionTreeNode(value=np.bincount(y).argmax())\n",
        "\n",
        "        feature, threshold = best_split\n",
        "\n",
        "        # Разделение данных\n",
        "        X_left, y_left, X_right, y_right = self._split(X, y, feature, threshold)\n",
        "        if len(y_left) < self.min_samples_leaf or len(y_right) < self.min_samples_leaf:\n",
        "            return DecisionTreeNode(value=np.bincount(y).argmax())\n",
        "\n",
        "        left_child = self._build_tree(X_left, y_left, depth + 1)\n",
        "        right_child = self._build_tree(X_right, y_right, depth + 1)\n",
        "\n",
        "        return DecisionTreeNode(feature, threshold, left_child, right_child)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build_tree(X, y, 0)\n",
        "\n",
        "    def _predict(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] < node.threshold:\n",
        "            return self._predict(x, node.left)\n",
        "        else:\n",
        "            return self._predict(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict(x, self.root) for x in X])\n",
        "\n",
        "class DecisionTreeRegressorCustom:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.root = None\n",
        "\n",
        "    def _mse(self, y):\n",
        "        return np.mean((y - np.mean(y)) ** 2)\n",
        "\n",
        "    def _split(self, X, y, feature, threshold):\n",
        "        left_indices = np.where(X[:, feature] < threshold)[0]\n",
        "        right_indices = np.where(X[:, feature] >= threshold)[0]\n",
        "        return X[left_indices], y[left_indices], X[right_indices], y[right_indices]\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_score = float('inf')  # Лучший критерий разбиения (минимальный MSE)\n",
        "        best_split = None\n",
        "\n",
        "        for feature in range(X.shape[1]):  # Перебор всех признаков\n",
        "            thresholds = np.unique(X[:, feature])  # Уникальные значения признака\n",
        "            for threshold in thresholds:\n",
        "                # Разбиение данных\n",
        "                X_left, y_left, X_right, y_right = self._split(X, y, feature, threshold)\n",
        "\n",
        "                # Проверка, что оба подмножества достаточно велики\n",
        "                if len(y_left) < self.min_samples_leaf or len(y_right) < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                # Вычисление MSE\n",
        "                score = (len(y_left) * self._mse(y_left) + len(y_right) * self._mse(y_right)) / len(y)\n",
        "                if score < best_score:\n",
        "                    best_score = score\n",
        "                    best_split = (feature, threshold)\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        # Условие остановки\n",
        "        if (len(np.unique(y)) == 1 or depth == self.max_depth or\n",
        "            len(y) < self.min_samples_split):\n",
        "            return DecisionTreeNode(value=np.mean(y))\n",
        "\n",
        "        # Найти лучшее разбиение\n",
        "        best_split = self._best_split(X, y)\n",
        "        if best_split is None:\n",
        "            return DecisionTreeNode(value=np.mean(y))\n",
        "\n",
        "        feature, threshold = best_split\n",
        "\n",
        "        # Разделение данных\n",
        "        X_left, y_left, X_right, y_right = self._split(X, y, feature, threshold)\n",
        "        if len(y_left) < self.min_samples_leaf or len(y_right) < self.min_samples_leaf:\n",
        "            return DecisionTreeNode(value=np.mean(y))\n",
        "\n",
        "        left_child = self._build_tree(X_left, y_left, depth + 1)\n",
        "        right_child = self._build_tree(X_right, y_right, depth + 1)\n",
        "\n",
        "        return DecisionTreeNode(feature, threshold, left_child, right_child)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build_tree(X, y, 0)\n",
        "\n",
        "    def _predict(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] < node.threshold:\n",
        "            return self._predict(x, node.left)\n",
        "        else:\n",
        "            return self._predict(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict(x, self.root) for x in X])\n",
        "\n",
        "class CustomRandomForestClassifier:\n",
        "    def __init__(self, n_estimators=10, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=None, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "\n",
        "    def _bootstrap_sample(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return X[indices], y[indices]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(self.random_state)\n",
        "        self.trees = []\n",
        "        for _ in range(self.n_estimators):\n",
        "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
        "            tree = DecisionTreeClassifierCustom(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf\n",
        "            )\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=tree_predictions)\n",
        "\n",
        "\n",
        "class CustomRandomForestRegressor:\n",
        "    def __init__(self, n_estimators=10, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=None, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_features = max_features\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "\n",
        "    def _bootstrap_sample(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return X[indices], y[indices]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(self.random_state)\n",
        "        self.trees = []\n",
        "        for _ in range(self.n_estimators):\n",
        "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
        "            tree = DecisionTreeRegressorCustom(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf\n",
        "            )\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        return np.mean(tree_predictions, axis=0)"
      ],
      "metadata": {
        "id": "LJQ_jZdxNXcO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модели и оценим их качество"
      ],
      "metadata": {
        "id": "WM26DCCFN7Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_class = scaler.fit_transform(X_train_class)\n",
        "X_test_class = scaler.transform(X_test_class)\n",
        "\n",
        "custom_rf_classifier = CustomRandomForestClassifier(n_estimators=10, max_depth=5, random_state=42)\n",
        "custom_rf_classifier.fit(X_train_class, y_train_class)\n",
        "\n",
        "y_pred_custom_class = custom_rf_classifier.predict(X_test_class)\n",
        "\n",
        "accuracy_custom = accuracy_score(y_test_class, y_pred_custom_class)\n",
        "f1_custom = f1_score(y_test_class, y_pred_custom_class, average='weighted')\n",
        "\n",
        "print(f\"Custom Random Forest Classifier - Accuracy: {accuracy_custom:.4f}, F1-Score: {f1_custom:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbLc7kTgN53z",
        "outputId": "291961c2-2398-48b4-b89f-cda65c4c3384"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Random Forest Classifier - Accuracy: 0.8667, F1-Score: 0.8678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_reg = scaler.fit_transform(X_train_reg)\n",
        "X_test_reg = scaler.transform(X_test_reg)\n",
        "\n",
        "custom_rf_regressor = CustomRandomForestRegressor(n_estimators=10, max_depth=5, random_state=42)\n",
        "custom_rf_regressor.fit(X_train_reg, np.array(y_train_reg))\n",
        "\n",
        "y_pred_custom_reg = custom_rf_regressor.predict(X_test_reg)\n",
        "\n",
        "rmse_custom = root_mean_squared_error(y_test_reg, y_pred_custom_reg)\n",
        "r2_custom = r2_score(y_test_reg, y_pred_custom_reg)\n",
        "\n",
        "print(f\"Custom Random Forest Regressor - RMSE: {rmse_custom:.4f}, R²: {r2_custom:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCtARHJqTeNj",
        "outputId": "5c580071-1284-4025-8076-ff420f5661a3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Random Forest Regressor - RMSE: 7.4933, R²: 0.7821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность вручную реализованных моделей оказалась похуже, чем у библиотечных, но все равно на приемлемом уровне."
      ],
      "metadata": {
        "id": "3JMizEMwVXZl"
      }
    }
  ]
}