{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №2: Проведение исследований с логистической и линейной регрессией"
      ],
      "metadata": {
        "id": "H3bBgZLgfQtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Выбор начальных условий"
      ],
      "metadata": {
        "id": "YsiYd-v8fTIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Был проведен в ЛР №1."
      ],
      "metadata": {
        "id": "FGJixl-yfaZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub scikit-learn numpy pandas matplotlib seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DALwnlrEfYGm",
        "outputId": "aa9810fb-a7d8-4cc2-cb87-fdf09c45f128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "cQr5Wmffffwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачивание Date Fruit Dataset\n",
        "date_fruit_path = kagglehub.dataset_download(\"muratkokludataset/date-fruit-datasets\")\n",
        "\n",
        "# Чтение Excel-файла\n",
        "date_fruit_data = pd.read_excel(f\"{date_fruit_path}/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDCzojinfpzj",
        "outputId": "09c606c5-6f41-4894-c394-e95e5d8660d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачивание Concrete Compressive Strength\n",
        "concrete_strength_path = kagglehub.dataset_download(\"niteshyadav3103/concrete-compressive-strength\")\n",
        "\n",
        "# Чтение CSV-файла\n",
        "concrete_data = pd.read_csv(f\"{concrete_strength_path}/Concrete Compressive Strength.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u-79z6xfwwP",
        "outputId": "9571808a-ff5d-4adc-9423-cb1f7443101d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/niteshyadav3103/concrete-compressive-strength?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14.1k/14.1k [00:00<00:00, 6.06MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "2G4OV2T3gBS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, root_mean_squared_error, r2_score, make_scorer\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "ujoGRbaMf9l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделим датасет для классификации на обучающую и тестовую выборки"
      ],
      "metadata": {
        "id": "gtWN-lWHh6TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на признаки и целевую переменную\n",
        "X_class = date_fruit_data.drop(columns=['Class'])\n",
        "y_class = date_fruit_data['Class']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
        ")\n",
        "\n",
        "# Преобразование целевой переменной\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_class = label_encoder.fit_transform(y_train_class)\n",
        "y_test_class = label_encoder.transform(y_test_class)"
      ],
      "metadata": {
        "id": "VxB2JRmjh67Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогично разделим датасет для регрессии"
      ],
      "metadata": {
        "id": "OOVh55mViNo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на признаки и целевую переменную\n",
        "X_reg = concrete_data.drop(columns=['Concrete compressive strength '])\n",
        "y_reg = concrete_data['Concrete compressive strength ']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "7b-yxscKiPeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модели для классификации и регрессии из Sklearn и оценим их. Для логистической регрессии нам требуется обязательный препроцессинг данных с помощью StandardScaler."
      ],
      "metadata": {
        "id": "TuCTmPuRiZW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_class = scaler.fit_transform(X_train_class)\n",
        "X_test_class = scaler.transform(X_test_class)\n",
        "\n",
        "logistic = LogisticRegression(max_iter=10000)\n",
        "logistic.fit(X_train_class, y_train_class)\n",
        "\n",
        "y_pred_class = logistic.predict(X_test_class)\n",
        "\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "f1 = f1_score(y_test_class, y_pred_class, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_TwkMg4iY0A",
        "outputId": "250fd9f3-8716-48d3-8466-5f18e863ef9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9222\n",
            "F1-Score: 0.9208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regressor = LinearRegression()\n",
        "linear_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "y_pred_reg = linear_regressor.predict(X_test_reg)\n",
        "\n",
        "rmse = root_mean_squared_error(y_test_reg, y_pred_reg)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1x6DxahkUy8",
        "outputId": "7cedaaf4-a635-4996-990c-44291c4eed2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 9.7967\n",
            "R²: 0.6275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, точность для встроенной в Sklearn модели логистической регрессии получилась отличной (92.7% точности). Для модели линейной регрессии среднеквадратичная ошибка составила 9.79, что несколько хуже бейзлайна для KNN-регрессора. Попробуем улучшить бейзлайн."
      ],
      "metadata": {
        "id": "15h0bXEfl2cx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "epAJ4JIlmg89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для улучшения бейзлайна для логистичекой регрессии будем подбирать гиперпараметр C с помощью GridSearchCV. Для линейной регрессии добавим регуляризацию через Ridge (L2)."
      ],
      "metadata": {
        "id": "1C-nK55Zmltw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пайплайн с нормализацией и логистической регрессией\n",
        "pipeline_logistic = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logistic', LogisticRegression(max_iter=10000))\n",
        "])\n",
        "\n",
        "# Параметры для подбора\n",
        "param_grid_logistic = {\n",
        "    'logistic__C': [0.01, 0.1, 1, 10, 75, 1000],\n",
        "    'logistic__penalty': ['l2'],  # L2-регуляризация\n",
        "    'logistic__solver': ['lbfgs']  # Подходит для L2-регуляризации\n",
        "}\n",
        "\n",
        "# Подбор гиперпараметров\n",
        "grid_search_logistic = GridSearchCV(\n",
        "    pipeline_logistic,\n",
        "    param_grid_logistic,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search_logistic.fit(X_train_class, y_train_class)\n",
        "\n",
        "# Лучшие параметры и результаты\n",
        "best_params_logistic = grid_search_logistic.best_params_\n",
        "best_score_logistic = grid_search_logistic.best_score_\n",
        "print(f\"Лучшие параметры для Logistic Regression: {best_params_logistic}\")\n",
        "print(f\"Лучший F1-Score на кросс-валидации: {best_score_logistic:.4f}\")\n",
        "\n",
        "# Оценка на тестовой выборке\n",
        "y_pred_class = grid_search_logistic.best_estimator_.predict(X_test_class)\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "f1 = f1_score(y_test_class, y_pred_class, average='weighted')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cDsFKKlmkNd",
        "outputId": "20a46bbc-3bca-4e44-a0c9-d1a63423d073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Лучшие параметры для Logistic Regression: {'logistic__C': 1, 'logistic__penalty': 'l2', 'logistic__solver': 'lbfgs'}\n",
            "Лучший F1-Score на кросс-валидации: 0.9150\n",
            "Test Accuracy: 0.9278\n",
            "Test F1-Score: 0.9263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры для подбора\n",
        "param_grid_ridge = {\n",
        "    'alpha': [0.01, 0.1, 1, 10, 100, 1000]  # Параметр регуляризации\n",
        "}\n",
        "\n",
        "grid_search_ridge = GridSearchCV(\n",
        "    Ridge(),\n",
        "    param_grid_ridge,\n",
        "    cv=5,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search_ridge.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Лучшие параметры и результаты\n",
        "best_params_ridge = grid_search_ridge.best_params_\n",
        "best_score_ridge = -grid_search_ridge.best_score_\n",
        "print(f\"Лучшие параметры для Ridge Regression: {best_params_ridge}\")\n",
        "print(f\"Лучший RMSE на кросс-валидации: {best_score_ridge:.4f}\")\n",
        "\n",
        "# Оценка на тестовой выборке\n",
        "ridge_regressor = grid_search_ridge.best_estimator_\n",
        "y_pred_reg = ridge_regressor.predict(X_test_reg)\n",
        "rmse = root_mean_squared_error(y_test_reg, y_pred_reg)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "print(f\"Test R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce8q3IIHsmqb",
        "outputId": "0db95cdc-e7d2-4b0e-afe8-f53e7ba3f816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Лучшие параметры для Ridge Regression: {'alpha': 1000}\n",
            "Лучший RMSE на кросс-валидации: 10.6589\n",
            "Test RMSE: 9.7951\n",
            "Test R²: 0.6277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, результаты немного улучшились по сравнению с бейзлайном."
      ],
      "metadata": {
        "id": "I8-FVFdituar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "y7AVnF8Ft7u5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем собственную реализацию Logistic and Linear regression, затем обучим модели на тестовых данных и сравним по качеству с реализациями из Sklearn."
      ],
      "metadata": {
        "id": "N9NqLIW_uBdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid_function = lambda z: 1 / (1 + np.exp(-z))\n",
        "\n",
        "def optimize_gradients(gradient_fn, start_point, learning_rate, max_iter):\n",
        "    current_point = start_point\n",
        "    for _ in range(max_iter):\n",
        "        grad = gradient_fn(current_point)\n",
        "        current_point -= learning_rate * grad\n",
        "    return current_point\n",
        "\n",
        "\n",
        "class CustomLogisticRegression:\n",
        "    def __init__(self, *, lr=0.01, max_epochs=1000):\n",
        "        self._learning_rate = lr\n",
        "        self._max_epochs = max_epochs\n",
        "        self._parameters = None\n",
        "        self._X_train = None\n",
        "        self._y_train = None\n",
        "\n",
        "    def _compute_gradient(self, params):\n",
        "        assert self._X_train is not None\n",
        "        assert self._y_train is not None\n",
        "\n",
        "        samples, _ = self._X_train.shape\n",
        "        weights, bias = params[:-1], params[-1]\n",
        "        predictions = sigmoid_function(np.dot(self._X_train, weights) + bias)\n",
        "\n",
        "        weight_grad = np.dot(self._X_train.T, (predictions - self._y_train)) / samples\n",
        "        bias_grad = np.sum(predictions - self._y_train) / samples\n",
        "\n",
        "        return np.append(weight_grad, bias_grad)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        assert self._parameters is None\n",
        "\n",
        "        self._X_train = np.array(X)\n",
        "        self._y_train = np.array(y)\n",
        "        features = self._X_train.shape[1]\n",
        "\n",
        "        # Initialize parameters and optimize\n",
        "        initial_params = np.ones(features + 1) * 0.5\n",
        "        self._parameters = optimize_gradients(\n",
        "            self._compute_gradient, initial_params, self._learning_rate, self._max_epochs\n",
        "        )\n",
        "\n",
        "    def predict(self, X):\n",
        "        assert self._parameters is not None\n",
        "\n",
        "        weights, bias = self._parameters[:-1], self._parameters[-1]\n",
        "        linear_output = np.dot(X, weights) + bias\n",
        "        probabilities = sigmoid_function(linear_output)\n",
        "        return (probabilities >= 0.5).astype(int)\n",
        "\n",
        "class CustomLinearRegression:\n",
        "    def __init__(self):\n",
        "        self._coef_ = None\n",
        "\n",
        "    def _add_intercept(self, X):\n",
        "        rows = X.shape[0]\n",
        "        return np.hstack([np.ones((rows, 1)), X])\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_intercept = self._add_intercept(X)\n",
        "        XtX = np.dot(X_intercept.T, X_intercept)\n",
        "        Xty = np.dot(X_intercept.T, y)\n",
        "        self._coef_ = np.linalg.solve(XtX, Xty)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_intercept = self._add_intercept(X)\n",
        "        return np.dot(X_intercept, self._coef_)"
      ],
      "metadata": {
        "id": "-vuT3Qyut_Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модели и оценим их качество"
      ],
      "metadata": {
        "id": "4LjfuxRnuinv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score\n",
        "\n",
        "log_reg = CustomLogisticRegression(lr=0.1, max_epochs=1000)\n",
        "log_reg.fit(X_train_class, y_train_class)\n",
        "y_pred_class = log_reg.predict(X_test_class)\n",
        "\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "f1 = f1_score(y_test_class, y_pred_class, average=\"weighted\")\n",
        "\n",
        "print(f\"Custom Logistic Regression - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "lin_reg = CustomLinearRegression()\n",
        "lin_reg.fit(X_train_reg, y_train_reg)\n",
        "y_pred_reg = lin_reg.predict(X_test_reg)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"Custom Linear Regression - RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_MD3-wEulN2",
        "outputId": "09913604-7847-43ea-f8b2-026287b6ce71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Logistic Regression - Accuracy: 0.1444, F1-Score: 0.0452\n",
            "Custom Linear Regression - RMSE: 9.7967, R²: 0.6275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, точность и F1-Score логистической модели сильно упали, а показатели линейной - остались примерно теми же."
      ],
      "metadata": {
        "id": "OCcvyRE67J3j"
      }
    }
  ]
}